{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IY-_Zy_b71lD"
      },
      "source": [
        "# Implementation of MCP Neuron for AND and OR Function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Fu-YDOe_8GJi"
      },
      "outputs": [],
      "source": [
        "def MCP_Neurons_AND(X1, X2, T):\n",
        "  \"\"\"\n",
        "  This functions implements basic AND operations with MCP Neuron for two inputs.\n",
        "  Arguments:\n",
        "  Inputs:\n",
        "  X1 (1 nd array): An array of binary values.\n",
        "  X2 (1 nd array): An array of binary values.\n",
        "  Output:\n",
        "  state_neuron(1D-list): An state of neuron 1 0r 0 for the particular inputs.\n",
        "  \"\"\"\n",
        "  assert len(X1) == len(X2)\n",
        "  ### YOUR CODE HERE ###\n",
        "  # Perform an element wise addition of two input arrays stored in a new array(list):\n",
        "  # Create a new array to put all the prediction let's name that a state_neuron.\n",
        "  # Append 1 in sate_neuron if sum (element) of above list is above Threshold else append 0.\n",
        "  # Perform element-wise addition and store in a new list\n",
        "  element_wise_sum = [x1 + x2 for x1, x2 in zip(X1, X2)]\n",
        "\n",
        "  # Create a new list to store neuron states\n",
        "  state_neuron = []\n",
        "\n",
        "  # Append 1 if sum is above threshold, otherwise append 0\n",
        "  for element_sum in element_wise_sum:\n",
        "    if element_sum >= T:\n",
        "      state_neuron.append(1)\n",
        "    else:\n",
        "      state_neuron.append(0)\n",
        "  return state_neuron"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2-lKfat8ocN",
        "outputId": "e3af9b73-7a0b-4d12-e1f2-65c33d7bbcca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Output of AND gate for inputs [0, 0, 1, 1] and [0, 1, 0, 1] with threshold 2: [0, 0, 0, 1]\n"
          ]
        }
      ],
      "source": [
        "# Example usage for MCP_Neurons_AND function\n",
        "X1 = [0, 0, 1, 1]\n",
        "X2 = [0, 1, 0, 1]\n",
        "T = 2  # Threshold value\n",
        "\n",
        "# Call the MCP_Neurons_AND function\n",
        "result = MCP_Neurons_AND(X1, X2, T)\n",
        "\n",
        "# Print the result\n",
        "print(f\"Output of AND gate for inputs {X1} and {X2} with threshold {T}: {result}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "7xaMXlLT9FHC"
      },
      "outputs": [],
      "source": [
        "def MCP_Neurons_OR(X1, X2, T):\n",
        "    \"\"\"\n",
        "    This function implements basic OR operations with MCP Neuron for two inputs.\n",
        "    Arguments:\n",
        "    Inputs:\n",
        "    X1 (1D array): An array of binary values.\n",
        "    X2 (1D array): An array of binary values.\n",
        "    Output:\n",
        "    state_neuron (1D list): The state of the neuron (1 or 0) for the particular inputs.\n",
        "    \"\"\"\n",
        "    assert len(X1) == len(X2)\n",
        "    ### YOUR CODE HERE ###\n",
        "    # Perform an element wise addition of two input arrays stored in a new array(list):\n",
        "    # Create a new array to put all the prediction let's name that a state_neuron.\n",
        "    # Append 1 in sate_neuron if sum (element) of above list is above Threshold else append 0.\n",
        "\n",
        "    element_wise_sum = [x1 + x2 for x1, x2 in zip(X1, X2)]\n",
        "\n",
        "    state_neuron = []\n",
        "\n",
        "    for element_sum in element_wise_sum:\n",
        "        if element_sum >= T:\n",
        "            state_neuron.append(1)\n",
        "        else:\n",
        "            state_neuron.append(0)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    return state_neuron\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6H-YOy268_Jo",
        "outputId": "238dabe8-b3eb-4910-d9ca-f4aa8fa7198f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Output of OR gate for inputs [0, 0, 1, 1] and [0, 1, 0, 1] with threshold 1: [0, 1, 1, 1]\n"
          ]
        }
      ],
      "source": [
        "# Example usage for MCP_Neurons_OR function\n",
        "X1 = [0, 0, 1, 1]\n",
        "X2 = [0, 1, 0, 1]\n",
        "T = 1  # Threshold value for OR gate\n",
        "\n",
        "# Call the MCP_Neurons_OR function\n",
        "result_or = MCP_Neurons_OR(X1, X2, T)\n",
        "\n",
        "# Print the result\n",
        "print(f\"Output of OR gate for inputs {X1} and {X2} with threshold {T}: {result_or}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXfiVhIJ-YFY"
      },
      "source": [
        "• Question - 1: List out all the limitations of MCP - Neurons.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3aCqX6Z-b9A"
      },
      "source": [
        "1. Unable to Learn\n",
        "MCP neurons have fixed weights and thresholds and cannot learn from data or learn from experience and update weights.\n",
        "They require hand tuning of weights and are therefore not practical for real-world applications.\n",
        "2. Only Linearly Separable Problems\n",
        "MCP neurons only work for linearly separable problems (like AND, OR gates).\n",
        "They are unable to solve non-linearly separable problems (e.g., XOR problem), and this necessitated the creation of more sophisticated models like Perceptrons and Multi-Layer Neural Networks.\n",
        "3. Binary Output Limitation\n",
        "The model uses a step activation function, i.e., the output is 0 or 1.\n",
        "It is not able to handle continuous values, and this limits its applicability in real-world problems that include probability estimation.\n",
        "4. No Support for Multi-Layer Networks\n",
        "MCP neurons are single-layered and cannot be used to develop deep networks.\n",
        "They lack the feature extraction ability for intricate hierarchical features, different from modern deep learning algorithms.\n",
        "5. No Weight Adjustment Concept (Gradient Descent)\n",
        "There is no backpropagation or use of gradient descent to update weights in MCP.\n",
        "This diminishes its ability to learn and generalize from training data.\n",
        "6. No Time Dependence (No Memory)\n",
        "The model is not concerned with temporal dependencies and thus not suitable for sequential data (e.g., speech, time-series prediction).\n",
        "It lacks memory process as in Recurrent Neural Networks (RNNs)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sqj8vQlG-bGG"
      },
      "source": [
        "• Question - 2: Think if you can develop a logic to solve for XOR function using MCP Neuron.\n",
        "{Can you devise a if else rules.}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oChtVZ5e_Ki1"
      },
      "source": [
        "We can't because method is not linearly separable. But we can build logic with if else. Here logic consiste of"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EHlrNxvE_jZ4",
        "outputId": "5a499850-9e68-48aa-de8f-db1157c01556"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "1\n",
            "0\n"
          ]
        }
      ],
      "source": [
        "def mcp_xor(x1, x2):\n",
        "    if (x1 == 1 and x2 == 0) or (x1 == 0 and x2 == 1):\n",
        "        return 1  # XOR condition satisfied\n",
        "    else:\n",
        "        return 0  # Otherwise, return 0\n",
        "\n",
        "# Test cases\n",
        "print(mcp_xor(0, 0))  # Output: 0\n",
        "print(mcp_xor(0, 1))  # Output: 1\n",
        "print(mcp_xor(1, 0))  # Output: 1\n",
        "print(mcp_xor(1, 1))  # Output: 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Udsr86Dj_oXJ"
      },
      "source": [
        "Here the output is correctly calculating the output for logical XOR gate."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Apa9bfLIFJHe"
      },
      "source": [
        "# Implementation for 0 Vs. 1 Classification."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iom83mGLFP_1"
      },
      "source": [
        "## Step 1: Load the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BUhQJizb8LVZ",
        "outputId": "e934bc86-0ae9-4be9-9e72-654603000864"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7rkW58ct9IYq",
        "outputId": "e992605a-d732-4bc6-8862-e8e9406470c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature matrix shape: (12665, 784)\n",
            "Label vector shape: (12665,)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Load the dataset\n",
        "dataset_1 = pd.read_csv(\"/content/drive/MyDrive/AI ML/Week 3/mnist_0_and_1.csv\")  # Add the correct file path if necessary\n",
        "\n",
        "# Extract features and labels\n",
        "X = dataset_1.drop(columns=[\"label\"]).values  # 784 pixels\n",
        "y = dataset_1[\"label\"].values  # Labels (0 or 1)\n",
        "\n",
        "# Check the shape of the features and labels\n",
        "print(\"Feature matrix shape:\", X.shape)\n",
        "print(\"Label vector shape:\", y.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEQUG68nABqS"
      },
      "source": [
        "What does the shape of X represent?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIpDksLvACQO"
      },
      "source": [
        "Shape of X during row represent the single image of total 784 and for columns it represent single pixel location for all images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jlq0EY2jHheD"
      },
      "source": [
        "### Viewing the Dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "id": "XKY2qjhCHAZ7",
        "outputId": "4932b5c3-ce1a-43dc-eb16-2db126e74e48"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x500 with 10 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Separate images for label 0 and label 1\n",
        "images_0 = X[y == 0]  # Get all images with label 0\n",
        "images_1 = X[y == 1]  # Get all images with label 1\n",
        "\n",
        "fig, axes = plt.subplots(2, 5, figsize=(10, 5))\n",
        "\n",
        "# Check if the arrays have the required amount of data\n",
        "if len(images_0) < 5 or len(images_1) < 5:\n",
        "    print(\"Error: Not enough images in images_0 or images_1 to plot 5 images.\")\n",
        "else:\n",
        "    for i in range(5):\n",
        "        # Plot digit 0\n",
        "        axes[0, i].imshow(images_0[i].reshape(28, 28), cmap=\"gray\")\n",
        "        axes[0, i].set_title(\"Label: 0\")\n",
        "        axes[0, i].axis(\"off\")\n",
        "        # Plot digit 1\n",
        "        axes[1, i].imshow(images_1[i].reshape(28, 28), cmap=\"gray\")\n",
        "        axes[1, i].set_title(\"Label: 1\")\n",
        "        axes[1, i].axis(\"off\")\n",
        "    plt.suptitle(\"First 5 Images of 0 and 1 from MNIST Subset\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qyM34tbHIqGi"
      },
      "source": [
        "## Step - 2 - Initializing the Weights:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "SMsXaZ38HfBI"
      },
      "outputs": [],
      "source": [
        "# Initialize weights and bias\n",
        "weights = np.zeros(X.shape[1])  # 784 weights (one for each pixel)\n",
        "bias = 0\n",
        "learning_rate = 0.1\n",
        "epochs = 100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jp9G5MXgAsEq"
      },
      "source": [
        "What does the weights array represent in this context?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKSzxfpYAzN0"
      },
      "source": [
        "The array of weights is the priority of every pixel in determining whether the image is a \"0\" or a \"1.\"\n",
        "\n",
        "Since we have 784 pixels in each image, we start 784 weights, one for each pixel.\n",
        "These weights will be optimized in training to minimize classification mistakes.\n",
        "The learned final weights will dictate the extent of each pixel's impact on the decision boundary for image classification."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "un5wrGhrAyeO"
      },
      "source": [
        "Why are we initializing the weights to zero? What effect could this\n",
        "have on the training process?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsSkf82jA-Oz"
      },
      "source": [
        "Zero initialization of weights is a simple technique, setting all weights at the same initial point. The argument is:\n",
        "\n",
        "It gives gradient descent a fair start.\n",
        "It doesn't bias towards any pixel in the beginning.\n",
        "It isn't suitable for general models like logistic regression. But it causes trouble in neural networks:\n",
        "\n",
        "Symmetry Problem\n",
        "\n",
        "If all the weights start at 0, all the neurons of a layer get updated equally in backpropagation.\n",
        "This prevents the network from learning varied and informative features and makes all the neurons redundant.\n",
        "\n",
        "Slow Convergence\n",
        "\n",
        "If all the weights are 0, all the gradients are the same, which means slow updates.\n",
        "The model can fail to learn the best weights efficiently."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EvraDxaeRVeo"
      },
      "source": [
        "## Step - 3 - Make a Decision function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "6uVj75txLWQi"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def decision_function(X, weights, bias):\n",
        "    \"\"\"\n",
        "    Compute the predicted labels for the input data.\n",
        "\n",
        "    Parameters:\n",
        "    - X: Features (input data) as a numpy array of shape (n_samples, n_features)\n",
        "    - weights: Updated weights after training\n",
        "    - bias: Updated bias after training\n",
        "\n",
        "    Returns:\n",
        "    - y_pred_all: The predicted labels for the input data\n",
        "    \"\"\"\n",
        "    predictions = np.dot(X, weights) + bias\n",
        "    #####Your Code Here############  # Activation function (step function)\n",
        "    y_pred_all = np.where(predictions >= 0, 1, 0)\n",
        "    return y_pred_all"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AVZNGyRdI4I4"
      },
      "source": [
        "## Step - 3 - Implement the Perceptron Learning Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Dg1ocrycJWpA"
      },
      "outputs": [],
      "source": [
        "def train_perceptron(X, y, weights, bias, learning_rate=0.1, epochs=100):\n",
        "    \"\"\"\n",
        "    Train the perceptron using the Perceptron Learning Algorithm.\n",
        "\n",
        "    Parameters:\n",
        "    - X: Features (input data) as a numpy array of shape (n_samples, n_features)\n",
        "    - y: Labels (true output) as a numpy array of shape (n_samples,)\n",
        "    - weights: Initial weights as a numpy array of shape (n_features,)\n",
        "    - bias: Initial bias value (scalar)\n",
        "    - learning_rate: Learning rate for weight updates (default is 0.1)\n",
        "    - epochs: Number of iterations to train the model (default is 100)\n",
        "\n",
        "    Returns:\n",
        "    - weights: Updated weights after training\n",
        "    - bias: Updated bias after training\n",
        "    - accuracy: Total correct prediction.\n",
        "    \"\"\"\n",
        "    # Step 3: Perceptron Learning Algorithm\n",
        "    # Your Code here#\n",
        "    for epoch in range(epochs):\n",
        "        for i in range(len(X)):\n",
        "          prediction = decision_function(X[i], weights, bias)\n",
        "          if y[i] - prediction != 0:\n",
        "            weights += learning_rate * (y[i] - prediction) * X[i]\n",
        "            bias += learning_rate * (y[i] - prediction)\n",
        "\n",
        "    # Step 4: Calculate accuracy\n",
        "    y_pred_all = decision_function(X, weights, bias)\n",
        "    accuracy = np.mean(y_pred_all == y)\n",
        "\n",
        "    return weights, bias, accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0yWOROABeED"
      },
      "source": [
        "What is the purpose of the output = np.dot(X[i], weights) + bias line?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orCu2wbkBk6u"
      },
      "source": [
        "This establishes the raw activation value before using the step function (decision function).\n",
        "The output is finally passed on through a threshold function (say, step function) to obtain a binary prediction (0 or 1)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QfeZn0mQBjNX"
      },
      "source": [
        "\n",
        "  What happens when the prediction is wrong? How are the weights and\n",
        "bias updated?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqQTt4LdByQW"
      },
      "source": [
        "If the prediction is incorrect, the Perceptron Learning Rule updates the weights and bias to reduce future errors.\n",
        "\n",
        "When error we utilize the condition,\n",
        "if y[i] - prediction!= 0:\n",
        "        weights += learning_rate * (y[i] - prediction) * X[i]\n",
        "        bias += learning_rate * (y[i] - prediction)\n",
        "\n",
        "If the prediction is too low (0 instead of 1), the update increases weights for relevant pixels.\n",
        "\n",
        "If the prediction is too high (1 instead of 0), the update decreases weights for relevant pixels.\n",
        "\n",
        "This continues until the model classifies most samples correctly or reaches max epochs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HquUSZ0sBkI_"
      },
      "source": [
        "Why is the final accuracy important, and what do you expect it to be?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ewWjGeLCDbd"
      },
      "source": [
        "It is an estimate of how well the model has learned to accurately classify images.\n",
        "High accuracy suggests that the model can generalize well to novel, unseen data.\n",
        "\n",
        "Low accuracy suggests:\n",
        "The model isn't learning (possibly because the data or the learning rate is bad).\n",
        "The data are linearly inseparable (say, XOR), and a Perceptron cannot handle it.\n",
        "Expected Accuracy for MNIST (0 vs. 1 Classification)\n",
        "\n",
        "Since the numbers 0 and 1 are linearly separable, the Perceptron will come close to achieving 100% accuracy if properly trained.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Va6AGI6iMAG9"
      },
      "source": [
        "## Training the Perceptron"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cn8XBYuZLswI",
        "outputId": "ce973181-12f6-4403-f99f-5983fe8c85ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The Final Accuracy is:  1.0\n"
          ]
        }
      ],
      "source": [
        "# After training the model with the perceptron_learning_algorithm\n",
        "weights, bias, accuracy = train_perceptron(X, y, weights, bias)\n",
        "\n",
        "# Evaluate the model using the new function\n",
        "print(\"The Final Accuracy is: \", accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-SLq1jbSMKPm"
      },
      "source": [
        "## Step 5: Visualize Misclassified Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KAMz1RPGMN_A",
        "outputId": "9f29305f-70bb-4418-a2f9-51304c05693f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final Accuracy: 1.0000\n",
            "All images were correctly classified!\n"
          ]
        }
      ],
      "source": [
        "# Get predictions for all data points\n",
        "predictions = np.dot(X, weights) + bias\n",
        "y_pred = np.where(predictions >= 0, 1, 0)\n",
        "\n",
        "# Calculate final accuracy\n",
        "final_accuracy = np.mean(y_pred == y)\n",
        "print(f\"Final Accuracy: {final_accuracy:.4f}\")\n",
        "\n",
        "# Step 5: Visualize Misclassified Images\n",
        "misclassified_idx = np.where(y_pred != y)[0]\n",
        "if len(misclassified_idx) > 0:\n",
        "    fig, axes = plt.subplots(2, 5, figsize=(10, 5))\n",
        "    for ax, idx in zip(axes.flat, misclassified_idx[:10]):  # Show 10 misclassified images\n",
        "        ax.imshow(X[idx].reshape(28, 28), cmap=\"gray\")\n",
        "        ax.set_title(f\"Pred: {y_pred[idx]}, True: {y[idx]}\")\n",
        "        ax.axis(\"off\")\n",
        "    plt.suptitle(\"Misclassified Images\")\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"All images were correctly classified!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ct_UAn3ACRAF"
      },
      "source": [
        "What does misclassified idx store, and how is it used in this code?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVFwI4LnCUJB"
      },
      "source": [
        "The line:\n",
        "```python\n",
        "misclassified_idx = np.where(y_pred!= y)[0]\n",
        "```\n",
        "np.where(y_pred!= y)\n",
        "\n",
        "finds indices where predicted labels (y_pred) are not equal to the actual labels (y).\n",
        "misclassified_idx holds an array of indices of the misclassified images\n",
        "\n",
        "If there are misclassified images, the code selects up to 10 misclassified images with:\n",
        "\n",
        "for ax, idx in zip(axes.flat, misclassified_idx[:10]):\n",
        "\n",
        "X[idx] extracts the misclassified image from the dataset.\n",
        "\n",
        ".reshape(28, 28)\n",
        "\n",
        "re-shapes the flattened 784-pixel vector into a 28x28 grayscale image.\n",
        "\n",
        "The image is displayed with its predicted vs. true label using Matplotlib.\n",
        "If no images were misclassified, the code prints:\n",
        "\"All images were correctly classified!\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FAnDzaWICSpj"
      },
      "source": [
        "How do you interpret the result if the output is ”All images were\n",
        "correctly classified!”?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7sA86kEJC2gK"
      },
      "source": [
        "\n",
        "\n",
        "The perceptron learned to classify all 1s and 0s in the data correctly.\n",
        "This is to be expected as digits 0 and 1 are linearly separable, and hence can be discriminated by a single-layer perceptron very easily.\n",
        "\n",
        "Possible Overfitting\n",
        "\n",
        "If this happens on training data, it's a good thing (the model learned perfectly).\n",
        "But if this happens on test data, it may indicate overfitting, meaning the model memorized the training set rather than generalizing well."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
